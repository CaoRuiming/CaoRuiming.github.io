<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Raymond Cao&#39;s Website</title>
    <link>https://caoruiming.github.io/project/</link>
      <atom:link href="https://caoruiming.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 01 May 2020 12:30:30 -0400</lastBuildDate>
    <image>
      <url>https://caoruiming.github.io/images/icon_hu069a29ff56bd6bea5e334f163882e18c_26159_512x512_fill_lanczos_center_2.png</url>
      <title>Projects</title>
      <link>https://caoruiming.github.io/project/</link>
    </image>
    
    <item>
      <title>Brown Political Review Website</title>
      <link>https://caoruiming.github.io/project/brown-political-review/</link>
      <pubDate>Fri, 01 May 2020 12:30:30 -0400</pubDate>
      <guid>https://caoruiming.github.io/project/brown-political-review/</guid>
      <description>&lt;p&gt;The 
&lt;a href=&#34;http://brownpoliticalreview.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Brown Political Review&lt;/a&gt; (BPR) is a student run publication at Brown University. In the fall of 2018, I was hired by BPR to lead its effort to build a new website to replace its slow, aging one.&lt;/p&gt;
&lt;p&gt;The original website was an old WordPress site that used an outdated premade theme. Partnering with designers from the Creative Board of BPR, we planned out the look and functionality of the new website from the end of 2018 to the beginning of 2019. I completed the bulk of the website development over the summer of 2019 so that we could have a grand reveal of the new design during the fall 2020 activities fair at Brown University.&lt;/p&gt;
&lt;p&gt;We built the new website theme from scratch and used the following technologies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://wordpress.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WordPress 5&lt;/a&gt; as the CMS (content management system)&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://labs.tonik.pl/theme/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tonik&lt;/a&gt; starter theme as the base of the new theme&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://getbootstrap.com/docs/3.4/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bootstrap 3&lt;/a&gt; and 
&lt;a href=&#34;https://sass-lang.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SCSS&lt;/a&gt; for styling&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://jquery.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;jQuery&lt;/a&gt; for custom menu behavior&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://d3js.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;D3.js&lt;/a&gt; integration to support interactive content on posts&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://www.advancedcustomfields.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Advanced Custom Fields&lt;/a&gt; for customizing page elements without code changes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We also performed content migration and changed 
&lt;a href=&#34;https://www.digitalocean.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;hosting services&lt;/a&gt; as part of this project.&lt;/p&gt;
&lt;p&gt;You can see the website at &lt;a href=&#34;http://brownpoliticalreview.org/&#34;&gt;http://brownpoliticalreview.org/&lt;/a&gt;. According to page loading benchmarks from 
&lt;a href=&#34;https://tools.pingdom.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pingdom&lt;/a&gt;, this website loads up to 10 times faster than the one that it replaces.&lt;/p&gt;
&lt;p&gt;Currently, I continue to lead the development and maintenance of the Brown Political Review&amp;rsquo;s website.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Detecting Fake News with CNNs &amp; RNNs</title>
      <link>https://caoruiming.github.io/project/gradient-ascent/</link>
      <pubDate>Sun, 01 Dec 2019 17:36:03 -0400</pubDate>
      <guid>https://caoruiming.github.io/project/gradient-ascent/</guid>
      <description>&lt;p&gt;As the final project of Brown University&amp;rsquo;s 
&lt;a href=&#34;http://cs.brown.edu/courses/csci1470/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep Learning&lt;/a&gt; course, I teamed up with 3 classmates to reimplement the models and reproduce the results from the paper 
&lt;a href=&#34;https://arxiv.org/pdf/1806.11316.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Fake News Identification on Twitter with Hybrid CNN and RNN Models&lt;/em&gt; (2018)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We built three models using 
&lt;a href=&#34;https://www.tensorflow.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TensorFlow 2&lt;/a&gt; that classified social media posts (in particular, Tweets), on 5 levels of truthfulness (levels defined by the 
&lt;a href=&#34;https://github.com/thiagorainmaker77/liar_dataset&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Liar Dataset&lt;/a&gt;):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;an LSTM RNN&lt;/li&gt;
&lt;li&gt;an LSTM with dropout regularization&lt;/li&gt;
&lt;li&gt;an LSTM with a 1D CNN&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My role in the project was pair programming with Daniel Kostovetsky to put together the three TensorFlow models. I also added on a live demo component for our project.&lt;/p&gt;
&lt;p&gt;To see our final report containing our results, you can 
&lt;a href=&#34;final_report.pdf&#34;&gt;download it here&lt;/a&gt;. Below is an excerpt from our conclusion.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Determining the truthfulness of a statement without context is a difficult problem. We were only able to achieve a 25.78% accuracy on our dataset, which may seem low, but is close to the paper’s 27% accuracy. For reference, we attempted to classify training examples by hand and achieved an accuracy that was far less than 25.78%, and in fact, no better than random guessing. Many statements in our dataset, such as “The economy bled $24 billion due to the government shutdown,” are virtually impossible to factually evaluate without an external reference. Others, such as “We have a federal government that thinks they have the authority to regulate our toilet seats,” are subjective, opinionated, or don’t have a well-defined truth value. Some statements did contain certain words that made them identifiable as true, or more frequently, false. For instance, the sentence “In the case of a catastrophic event, the Atlanta-area offices of the Centers for Disease Control and Prevention will self-destruct,” includes the word ‘self-destruct’ that is associated with fictional stories, implying that it is false. Perhaps our model learned to make classifications by looking for such words.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You can find the source code of the project at &lt;a href=&#34;https://github.com/CaoRuiming/gradient-ascent-project&#34;&gt;https://github.com/CaoRuiming/gradient-ascent-project&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Photo by 
&lt;a href=&#34;https://unsplash.com/@mbaumi?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mika Baumeister&lt;/a&gt; on 
&lt;a href=&#34;https://unsplash.com/s/photos/fake-news?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unsplash&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data Science on U.S. Broadband</title>
      <link>https://caoruiming.github.io/project/broadband-data/</link>
      <pubDate>Wed, 01 May 2019 18:09:34 -0400</pubDate>
      <guid>https://caoruiming.github.io/project/broadband-data/</guid>
      <description>&lt;p&gt;This was my final project for Brown University&amp;rsquo;s 
&lt;a href=&#34;https://cs.brown.edu/courses/csci1951-a/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Data Science&lt;/a&gt; course, and I worked in a group with 3 other classmates.&lt;/p&gt;
&lt;p&gt;The purpose of our project was to pull in U.S. Census data and combine it with state and FCC-provided broadband deployment data to gain insight on trends in inequal American broadband availability and get a general sense of the state of deployment.&lt;/p&gt;
&lt;p&gt;My personal role was performing a k-mean analysis on internet access choice in New York to find if the proportions of forms of broadband deployment could reveal the most economical way to build out networks and close the digital divide.&lt;/p&gt;
&lt;p&gt;Our intermediate and final blog reports on this project can be read at &lt;a href=&#34;https://caoruiming.github.io/data-science-final-project/&#34;&gt;https://caoruiming.github.io/data-science-final-project/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can see the source code of the project at &lt;a href=&#34;https://github.com/CaoRuiming/data-science-final-project&#34;&gt;https://github.com/CaoRuiming/data-science-final-project&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Photo by 
&lt;a href=&#34;https://unsplash.com/@markusspiske?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Markus Spiske&lt;/a&gt; on 
&lt;a href=&#34;https://unsplash.com/s/photos/broadband?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Unsplash&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Chinese Translation Application</title>
      <link>https://caoruiming.github.io/project/biang-biang/</link>
      <pubDate>Tue, 01 May 2018 17:19:22 -0400</pubDate>
      <guid>https://caoruiming.github.io/project/biang-biang/</guid>
      <description>&lt;p&gt;During 
&lt;a href=&#34;https://2018.hackatbrown.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hack@Brown 2018&lt;/a&gt;, I worked with three other students to design and develop a 
&lt;a href=&#34;https://reactjs.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;React.js&lt;/a&gt; app that took in Chinese text and output the corresponding pinyin (a writing system that denotes the pronunciation of Chinese characters) as well as English translations of user-selected text. The application was built entirely out of open source technologies, works offline, and works across any platform that supports web browsing.&lt;/p&gt;
&lt;p&gt;The purpose of this project was to assist English-speaking students in learning to read (simplified) Chinese. Every member of our hackathon project group enjoyed reading translated Chinese web novels in our free time, so we decided to build a tool to help us read the &amp;ldquo;raws&amp;rdquo; (i.e. the source material written in the original language).&lt;/p&gt;
&lt;p&gt;My primary role on the team was the React.js developer, and I lead the technical development of our app.&lt;/p&gt;
&lt;p&gt;You can view the source code of this project, Biang Biang, at &lt;a href=&#34;https://github.com/CaoRuiming/biangbiang&#34;&gt;https://github.com/CaoRuiming/biangbiang&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
